{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-14T15:58:35.895357Z",
     "start_time": "2025-07-14T15:58:20.601377Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from utils.dataset_TinyImage import load_data\n",
    "from utils.OpenGAN_arc import Discriminator\n",
    "from utils import train_openganII\n",
    "from utils import visualize_results\n",
    "from utils import evaluate_opengan\n",
    "from utils.extr_fea import *\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "37c4af694377a2e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T15:58:35.988928Z",
     "start_time": "2025-07-14T15:58:35.905353Z"
    }
   },
   "source": [
    "config = {\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"batch_size\": 128,\n",
    "    \"num_closed_classes\": 200,  # TinyImageNet类别数\n",
    "    \"image_size\": 64,  # 统一图像尺寸\n",
    "    \"feature_dim\": 512,  # ResNet18特征维度\n",
    "\n",
    "    # 分类器训练参数\n",
    "    \"classifier_lr\": 0.001,\n",
    "    \"classifier_epochs\": 1,\n",
    "    \"classifier_momentum\": 0.9,\n",
    "    \"classifier_weight_decay\": 5e-4,\n",
    "\n",
    "    # OpenGAN参数\n",
    "    \"opengan_lr\": 1e-4,\n",
    "    \"opengan_epochs\": 1,\n",
    "    \"lambda_g\": 0.5,\n",
    "    \"lambda_gp\": 10.0,  # 梯度惩罚系数\n",
    "    \"d_train_ratio\": 5,  # 判别器训练次数/生成器训练次数\n",
    "\n",
    "    # 数据集路径\n",
    "    \"tinyimagenet_path\": \"./data/tiny-imagenet-200\",\n",
    "    \"output_dir\": \"./results_setup2\",\n",
    "    \"save_dir\": \"./results_setup2\",\n",
    "\n",
    "    # 开集数据集\n",
    "    \"open_datasets\": [\"CIFAR10\", \"SVHN\", \"MNIST\"],\n",
    "}\n",
    "\n",
    "os.makedirs(config[\"output_dir\"], exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9970bc88415d7d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T16:00:57.447017Z",
     "start_time": "2025-07-14T15:58:36.630161Z"
    }
   },
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # 加载TinyImageNet数据集\n",
    "    data_dict = load_data(config)\n",
    "    closed_train_loader = DataLoader(\n",
    "        data_dict[\"closed\"][\"train\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True\n",
    "    )\n",
    "    closed_val_loader = DataLoader(\n",
    "        data_dict[\"closed\"][\"val\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=False\n",
    "    )\n",
    "    # 训练闭集分类器\n",
    "    classifier = train_classifierII(closed_train_loader, closed_val_loader,config)\n",
    "    # 加载开集数据集\n",
    "    open_train_data = data_dict[\"open\"][\"CIFAR10\"][\"train\"]\n",
    "    open_train_loader = DataLoader(\n",
    "        open_train_data,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_data = {\n",
    "    \"closed\": closed_val_loader,\n",
    "    \"open\": DataLoader(\n",
    "        data_dict[\"open\"][\"CIFAR10\"][\"test\"],  # 或其它你想用的 open 数据集\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=False\n",
    "    )\n",
    "}\n",
    "    # 训练OpenGAN\n",
    "    discriminator = train_openganII(\n",
    "        classifier, open_train_loader, val_data, config\n",
    "    )\n",
    "\n",
    "    best_discriminator = Discriminator().to(config[\"device\"])\n",
    "    best_discriminator.load_state_dict(\n",
    "        torch.load(os.path.join(config[\"output_dir\"], \"best_discriminator.pth\"))\n",
    "    )\n",
    "    visualize_results(\n",
    "        classifier, best_discriminator, data_dict[\"closed\"][\"test\"], data_dict[\"open\"][\"CIFAR10\"][\"test\"], config\n",
    "    )\n",
    "    # 最终测试评估\n",
    "    test_auroc = evaluate_opengan(\n",
    "        best_discriminator, classifier, data_dict[\"closed\"][\"test\"], data_dict[\"open\"][\"CIFAR10\"][\"test\"], config\n",
    "    )\n",
    "    print(f\"\\n最终测试集AUROC: {test_auroc:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载TinyImageNet数据集...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data\\train_32x32.mat\n",
      "Using downloaded and verified file: ./data\\test_32x32.mat\n",
      "\n",
      "训练闭集分类器...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "分类器 Epoch 1/1:  16%|█▌        | 99/625 [02:12<11:42,  1.34s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 15\u001B[0m\n\u001B[0;32m      9\u001B[0m closed_val_loader \u001B[38;5;241m=\u001B[39m DataLoader(\n\u001B[0;32m     10\u001B[0m     data_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     11\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     12\u001B[0m     shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     13\u001B[0m )\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# 训练闭集分类器\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m classifier \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_classifierII\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosed_train_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosed_val_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# 加载开集数据集\u001B[39;00m\n\u001B[0;32m     17\u001B[0m open_train_data \u001B[38;5;241m=\u001B[39m data_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopen\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCIFAR10\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mE:\\Projects\\Learn\\OpenGAN\\utils\\extr_fea.py:120\u001B[0m, in \u001B[0;36mtrain_classifierII\u001B[1;34m(train_loader, val_loader, config)\u001B[0m\n\u001B[0;32m    117\u001B[0m classifier\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m    118\u001B[0m running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m--> 120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_loader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m分类器 Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassifier_epochs\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    121\u001B[0m     images, labels \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m\"\u001B[39m]), labels\u001B[38;5;241m.\u001B[39mto(config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    123\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\dl_torch\\lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\dl_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\dl_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\dl_torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\dl_torch\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\dl_torch\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32mE:\\Projects\\Learn\\OpenGAN\\utils\\dataset_TinyImage.py:101\u001B[0m, in \u001B[0;36mTINYIMAGENET.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     99\u001B[0m curLabel \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(curLabel, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m    100\u001B[0m curImage \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimageNameList[idx]\n\u001B[1;32m--> 101\u001B[0m curImage \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurImage\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    102\u001B[0m curImage \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(curImage)\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m curImage, curLabel\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\dl_torch\\lib\\site-packages\\PIL\\Image.py:3465\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3462\u001B[0m     filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(fp)\n\u001B[0;32m   3464\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[1;32m-> 3465\u001B[0m     fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3466\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   3467\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308974ff3221ddfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
